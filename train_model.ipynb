{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras.applications import EfficientNetV2B0\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_path = \"./train_dataset/\"\n",
    "\n",
    "seed=np.random.randint(0,100000)\n",
    "\n",
    "train_data = tf.keras.utils.image_dataset_from_directory(\n",
    "    training_data_path,\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    batch_size=32,\n",
    "    image_size=(256, 256),\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=seed\n",
    ")\n",
    "\n",
    "validation_data = tf.keras.utils.image_dataset_from_directory(\n",
    "    training_data_path,\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    batch_size=32,\n",
    "    image_size=(256, 256),\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=seed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentation = tf.keras.Sequential([\n",
    "        tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "        tf.keras.layers.RandomRotation(0.08), # +- 30 degrees\n",
    "        tf.keras.layers.RandomTranslation(0.1, 0.1, fill_mode=\"nearest\"),\n",
    "        tf.keras.layers.RandomZoom(0.1, fill_mode=\"nearest\"),\n",
    "        tf.keras.layers.RandomContrast(0.15),\n",
    "        tf.keras.layers.RandomBrightness(0.15),\n",
    "        tf.keras.layers.GaussianNoise(0.2)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = EfficientNetV2B0(weights=\"imagenet\", include_top=False)\n",
    "\n",
    "base_model.trainable = False\n",
    "#for layer in base_model.layers[:80]:\n",
    "#    layer.trainable = False\n",
    "\n",
    "inputs = tf.keras.layers.Input(shape=(256,256,3))\n",
    "x = augmentation(inputs)\n",
    "x = tf.keras.applications.efficientnet_v2.preprocess_input(x)\n",
    "x = base_model(x)\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "predictions = tf.keras.layers.Dense(6, activation='softmax')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=5e-4) , loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(monitor=\"val_loss\",\n",
    "                                                filepath=\"./best_model.keras\",\n",
    "                                                verbose=1,\n",
    "                                                save_best_only=True)\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\",\n",
    "                                            patience=10,\n",
    "                                            restore_best_weights=True)\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\",\n",
    "                                                factor=0.5,\n",
    "                                                patience=3,\n",
    "                                                verbose=1,\n",
    "                                                min_delta=0.0001,\n",
    "                                                min_lr=0.000001)\n",
    "\n",
    "callbacks = [checkpoint, early_stop, reduce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_data,\n",
    "    validation_data=validation_data,\n",
    "    epochs=300,\n",
    "    verbose=1,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history[\"loss\"], label=\"loss\")\n",
    "plt.plot (history.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history[\"accuracy\"], label=\"accuracy\")\n",
    "plt.plot (history.history[\"val_accuracy\"], label=\"val_accuracy\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('./best_model.keras')\n",
    "\n",
    "num_classes = len(validation_data.class_names)\n",
    "conf_matrix = np.zeros((num_classes, num_classes), dtype=int)\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for images, labels in validation_data:\n",
    "    predictions = model.predict(images)\n",
    "    y_true_batch = np.argmax(labels, axis=1)\n",
    "    y_pred_batch = np.argmax(predictions, axis=1)\n",
    "    y_true.extend(y_true_batch)\n",
    "    y_pred.extend(y_pred_batch)\n",
    "    for true, pred in zip(y_true_batch, y_pred_batch):\n",
    "        conf_matrix[true, pred] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "for images, labels in validation_data:\n",
    "    y_pred.extend(np.argmax(model.predict(images), axis=1))\n",
    "    y_true.extend(np.argmax(labels.numpy(), axis=1))\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=validation_data.class_names, \n",
    "            yticklabels=validation_data.class_names)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
